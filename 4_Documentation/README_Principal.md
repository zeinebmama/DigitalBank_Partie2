# DigitalBank France â€“ Plateforme de Monitoring et DÃ©tection de Fraude

## ğŸ“Œ PrÃ©sentation GÃ©nÃ©rale

**DigitalBank France** est une nÃ©obanque innovante proposant des services bancaires 100% digitaux. Dans un contexte de digitalisation accrue des services financiers, la dÃ©tection proactive des fraudes et le monitoring en temps rÃ©el des systÃ¨mes sont devenus des enjeux critiques.

Ce projet acadÃ©mique, rÃ©alisÃ© dans le cadre du cursus **ESIC Paris**, consiste Ã  concevoir et dÃ©ployer une plateforme complÃ¨te de :
- **DÃ©tection automatisÃ©e de fraudes** via Machine Learning
- **Monitoring infrastructure** en temps rÃ©el
- **Dashboards dÃ©cisionnels** pour diffÃ©rents profils utilisateurs
- **Automatisation des alertes** et workflows de rÃ©ponse

### Contexte MÃ©tier

Les nÃ©obanques traitent des millions de transactions quotidiennes. La fraude bancaire reprÃ©sente un risque financier et rÃ©putationnel majeur. Les dÃ©fis incluent :
- DÃ©tection en temps rÃ©el des transactions suspectes
- RÃ©duction des faux positifs (legitimate transactions flagged as fraud)
- Monitoring de la disponibilitÃ© et performance des systÃ¨mes critiques
- TraÃ§abilitÃ© et conformitÃ© rÃ©glementaire (RGPD, DSP2, LCB-FT)

---

## ğŸ¯ Objectifs du Projet

### Objectifs Fonctionnels
1. **DÃ©tecter automatiquement les fraudes** via un modÃ¨le de Machine Learning entraÃ®nÃ© sur des donnÃ©es transactionnelles historiques
2. **Visualiser en temps rÃ©el** les indicateurs clÃ©s de performance (KPI) et les alertes
3. **Automatiser les workflows** de notification et d'escalade en cas d'incident
4. **Fournir des tableaux de bord** adaptÃ©s Ã  chaque profil mÃ©tier

### Objectifs Techniques
1. ImplÃ©menter une architecture scalable et rÃ©siliente
2. Garantir la sÃ©curitÃ© des donnÃ©es (chiffrement, RBAC, audit logs)
3. Assurer une disponibilitÃ© de 99,5% minimum (SLA)
4. Permettre l'extension future du systÃ¨me (nouveaux modÃ¨les, nouvelles sources de donnÃ©es)

### Objectifs PÃ©dagogiques
- MaÃ®triser une stack technologique moderne (Cloud, API, Data Engineering)
- Appliquer les bonnes pratiques DevOps et MLOps
- Produire une documentation professionnelle complÃ¨te

---

## ğŸ—ï¸ Architecture Globale

### Vue d'Ensemble

L'architecture suit un modÃ¨le **event-driven** avec sÃ©paration des responsabilitÃ©s :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Applications   â”‚â”€â”€â”€â”€â”€â–¶â”‚   API Gateway    â”‚â”€â”€â”€â”€â”€â–¶â”‚  Fraud Engine   â”‚
â”‚   DigitalBank   â”‚      â”‚  (Auth/Routing)  â”‚      â”‚  (ML Python)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚                          â”‚
                                  â–¼                          â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   Supabase DB    â”‚â—€â”€â”€â”€â”€â”€â”‚  Event Stream   â”‚
                         â”‚   (PostgreSQL)   â”‚      â”‚  (Transactions) â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼             â–¼             â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Metabase â”‚  â”‚   Make   â”‚  â”‚ Grafana  â”‚
            â”‚Dashboardsâ”‚  â”‚Workflows â”‚  â”‚Monitoringâ”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flux de DonnÃ©es

1. **Ingestion** : Les transactions sont envoyÃ©es Ã  l'API via HTTPS
2. **Scoring** : Le modÃ¨le ML calcule un score de risque (0-100)
3. **Persistance** : Transactions + scores sont stockÃ©s dans Supabase
4. **Alerting** : Si score > seuil, dÃ©clenchement d'un workflow Make.com
5. **Visualisation** : Dashboards Metabase interrogent la base en temps rÃ©el
6. **Monitoring** : Prometheus collecte les mÃ©triques systÃ¨me, Grafana affiche

---

## ğŸ”§ Composants Techniques

### 1. Base de DonnÃ©es â€“ Supabase (PostgreSQL)

**RÃ´le** : Stockage centralisÃ© des donnÃ©es transactionnelles, utilisateurs, logs et alertes.

**CaractÃ©ristiques** :
- PostgreSQL 15+ avec extensions PostGIS (gÃ©olocalisation) et pgcrypto (chiffrement)
- Row-Level Security (RLS) activÃ© pour isolation multi-tenant
- RÃ©plication asynchrone pour haute disponibilitÃ©
- Backups automatiques quotidiens avec rÃ©tention 30 jours

**SchÃ©ma Principal** :
- `transactions` : historique des transactions (montant, merchant, user_id, timestamp, fraud_score)
- `users` : profils clients (KYC data, risk_level)
- `alerts` : alertes de fraude gÃ©nÃ©rÃ©es automatiquement
- `audit_logs` : traÃ§abilitÃ© des actions utilisateurs et systÃ¨mes

### 2. API de DÃ©tection de Fraude â€“ Python

**RÃ´le** : Exposer un endpoint REST pour scorer en temps rÃ©el les transactions.

**Technologies** :
- Framework : **FastAPI** (asynchrone, haute performance)
- ModÃ¨le ML : **XGBoost** ou **Random Forest** (entraÃ®nÃ© sur dataset Kaggle "Credit Card Fraud Detection")
- DÃ©ploiement : **Docker** + orchestration via **Docker Compose** ou **Kubernetes**

**Features** :
- Endpoint `/predict` : scoring d'une transaction individuelle
- Endpoint `/batch` : scoring de masse (jusqu'Ã  10 000 transactions/requÃªte)
- Health checks automatiques (`/health`, `/metrics`)
- Rate limiting (100 req/s par client)
- Logging structurÃ© (JSON) vers Elasticsearch

**ModÃ¨le ML** :
- Variables d'entrÃ©e : `amount`, `merchant_category`, `hour`, `day_of_week`, `distance_from_home`, `transaction_velocity`
- Output : `fraud_probability` (0.0 Ã  1.0), `risk_level` (LOW/MEDIUM/HIGH/CRITICAL)
- Retraining hebdomadaire automatique avec MLflow

### 3. Dashboards â€“ Metabase

**RÃ´le** : Visualisation interactive des donnÃ©es pour diffÃ©rents profils utilisateurs.

**Dashboards ImplÃ©mentÃ©s** :

#### Dashboard 1 : Analyste de SÃ©curitÃ©
- **KPI** : Nombre de fraudes dÃ©tectÃ©es (jour/semaine/mois), taux de fraude, montant frauduleux
- **Graphiques** : 
  - Ã‰volution temporelle des fraudes (line chart)
  - Distribution gÃ©ographique (heatmap)
  - Top 10 merchants Ã  risque (bar chart)
- **Filtres** : pÃ©riode, pays, risk_level, montant min/max

#### Dashboard 2 : Service Client
- **Objectif** : Traiter les alertes et valider/invalider les fraudes signalÃ©es
- **Vues** :
  - Liste des alertes en attente de traitement
  - Historique transactionnel client (timeline)
  - Indicateurs de comportement (transaction velocity, montant moyen)
- **Actions** : Marquage fraude confirmÃ©e/faux positif, escalade vers analyste

#### Dashboard 3 : Monitoring Infrastructure
- **MÃ©triques systÃ¨me** :
  - DisponibilitÃ© API (uptime %)
  - Latence moyenne des requÃªtes (p50, p95, p99)
  - Taux d'erreur HTTP (4xx, 5xx)
  - Utilisation CPU/RAM/Disk des serveurs
- **Alertes infrastructure** : 
  - DB connection pool saturÃ©
  - Replication lag > 5 secondes
  - Disk usage > 80%

**Configuration** :
- Connexion directe Ã  Supabase via PostgreSQL driver
- Refresh automatique toutes les 30 secondes
- Export PDF/Excel des rapports planifiÃ©s (envoi email hebdomadaire)

### 4. Automatisation â€“ Make.com

**RÃ´le** : Orchestration des workflows de rÃ©ponse aux incidents.

**Workflows ImplÃ©mentÃ©s** :

#### Workflow 1 : Alerte Fraude Critique
```
Trigger : Nouvelle ligne dans table `alerts` avec risk_level = CRITICAL
â†“
Action 1 : Bloquer temporairement la carte (API DigitalBank)
â†“
Action 2 : Envoyer notification push au client (Firebase Cloud Messaging)
â†“
Action 3 : CrÃ©er ticket dans Jira pour Ã©quipe fraude
â†“
Action 4 : Envoyer SMS au client (Twilio)
â†“
Action 5 : Logger l'action dans audit_logs
```

#### Workflow 2 : RÃ©conciliation Quotidienne
```
Trigger : Cron job (tous les jours Ã  02h00 UTC)
â†“
Action 1 : Exporter les transactions du jour (CSV)
â†“
Action 2 : Uploader vers S3 bucket (archivage)
â†“
Action 3 : Envoyer rapport par email au CFO
```

#### Workflow 3 : Escalade Automatique
```
Trigger : Alerte non traitÃ©e depuis > 30 minutes
â†“
Action 1 : Envoyer notification Slack au manager
â†“
Action 2 : Appeler API PagerDuty (on-call engineer)
```

**Avantages** :
- No-code/Low-code : modifications rapides sans redÃ©ploiement
- Connecteurs natifs : 1000+ intÃ©grations disponibles
- Historique d'exÃ©cution : debugging facilitÃ©

### 5. Monitoring â€“ Prometheus + Grafana

**RÃ´le** : Supervision technique de l'infrastructure et des applications.

**Architecture** :
- **Prometheus** : collecte des mÃ©triques via scraping (pull model)
- **Exporters** : 
  - `node_exporter` : mÃ©triques systÃ¨me (CPU, RAM, Disk, Network)
  - `postgres_exporter` : mÃ©triques base de donnÃ©es (connections, queries/sec, cache hit ratio)
  - Custom exporter API : mÃ©triques applicatives (fraud_score_avg, api_response_time)
- **Grafana** : visualisation avec dashboards prÃ©-configurÃ©s + alerting

**Alertes Critiques** :
- API response time > 500ms pendant 5 minutes â†’ email + Slack
- Database connections > 90% du pool â†’ PagerDuty
- Disk usage > 85% â†’ Ticket Jira automatique
- Fraud detection model accuracy < 95% â†’ notification Ã©quipe Data Science

**Retention** :
- MÃ©triques brutes : 15 jours
- MÃ©triques agrÃ©gÃ©es (5min) : 90 jours
- MÃ©triques agrÃ©gÃ©es (1h) : 1 an

### Alternative : Stack ELK (Elasticsearch, Logstash, Kibana)

**Utilisation** : Centralisation et analyse des logs applicatifs.

- **Logstash** : ingestion et parsing des logs (JSON, Syslog)
- **Elasticsearch** : indexation full-text et recherche performante
- **Kibana** : exploration interactive des logs, crÃ©ation de visualisations

**Cas d'usage** :
- Debugging des erreurs API via recherche full-text
- Analyse des patterns d'attaque (tentatives de brute-force, SQL injection)
- Audit de conformitÃ© (qui a accÃ©dÃ© Ã  quoi, quand ?)

---

## ğŸ‘¥ Profils Utilisateurs et Permissions

### ModÃ¨le RBAC (Role-Based Access Control)

| RÃ´le | Permissions | AccÃ¨s Dashboards | AccÃ¨s API |
|------|------------|------------------|-----------|
| **Analyste SÃ©curitÃ©** | Lecture toutes transactions, Ã©criture sur alerts (validation), lecture logs | Dashboard SÃ©curitÃ©, Monitoring | GET /transactions, POST /alerts/validate |
| **Service Client** | Lecture transactions du client, Ã©criture notes, lecture alertes client | Dashboard Service Client | GET /transactions/:user_id, GET /alerts/:user_id |
| **Admin Infrastructure** | Lecture monitoring, gestion utilisateurs, configuration systÃ¨me | Monitoring Infrastructure, Admin Panel | GET /metrics, POST /config |
| **Data Scientist** | Lecture toutes donnÃ©es, Ã©criture modÃ¨les, accÃ¨s notebooks | Aucun (accÃ¨s direct DB) | POST /models/train, GET /models/metrics |
| **Compliance Officer** | Lecture audit_logs, export rapports rÃ©glementaires | Audit Dashboard | GET /audit_logs, GET /reports/aml |

### Authentification et SÃ©curitÃ©

- **SSO** : IntÃ©gration via OpenID Connect (Keycloak ou Auth0)
- **MFA** : Obligatoire pour les rÃ´les Admin et Analyste SÃ©curitÃ©
- **Session Management** : JWT tokens avec refresh token (durÃ©e 15 min / 7 jours)
- **IP Whitelisting** : AccÃ¨s API production limitÃ© aux IP du VPN entreprise

---

## âš™ï¸ FonctionnalitÃ©s Principales

### 1. DÃ©tection de Fraude en Temps RÃ©el
- Scoring ML avec latence < 100ms (p95)
- Support de 10 000 transactions/seconde
- Explainability : feature importance pour chaque prÃ©diction (SHAP values)
- A/B testing : comparaison de plusieurs modÃ¨les en production

### 2. Gestion des Alertes
- Priorisation automatique (CRITICAL > HIGH > MEDIUM > LOW)
- Assignment automatique selon charge des analystes
- SLA tracking : temps moyen de rÃ©solution < 15 minutes
- Feedback loop : marquage faux positif amÃ©liore le modÃ¨le

### 3. Reporting et Analytics
- Rapports rÃ©glementaires automatiques (SAR - Suspicious Activity Report)
- Export formats : PDF, Excel, CSV, JSON
- Planification : daily/weekly/monthly reports
- Custom reports via SQL editor (pour analystes avancÃ©s)

### 4. IntÃ©gration Externe
- **Webhooks** : notification temps rÃ©el vers systÃ¨mes tiers
- **API REST** : architecture dÃ©couplÃ©e, rÃ©utilisable
- **SDKs** : Python, JavaScript, Java clients pour intÃ©gration rapide

---

## ğŸ”’ SÃ©curitÃ© et ConformitÃ©

### SÃ©curitÃ© des DonnÃ©es

#### Chiffrement
- **At Rest** : AES-256 pour les donnÃ©es en base (PostgreSQL encrypted tablespaces)
- **In Transit** : TLS 1.3 obligatoire pour toutes les communications
- **Application Level** : Champs sensibles (numÃ©ro carte) chiffrÃ©s avec clÃ©s rotatives (KMS)

#### Anonymisation
- PII (Personally Identifiable Information) masquÃ© dans les logs
- Pseudonymisation des donnÃ©es d'entraÃ®nement ML
- Droit Ã  l'oubli (RGPD) : suppression automatique aprÃ¨s 5 ans

### Logging et Audit

- **Audit Trail** : Toute action sensible (accÃ¨s donnÃ©es client, modification alert) loggÃ©e
- **Retention** : 
  - Logs opÃ©rationnels : 90 jours
  - Audit logs : 7 ans (conformitÃ© rÃ©glementaire)
- **SIEM Integration** : Export vers Splunk pour corrÃ©lation cross-systÃ¨mes

### Tests de SÃ©curitÃ©

- **Pentesting** : Trimestriel par cabinet externe
- **SAST/DAST** : Scan automatique du code (SonarQube, OWASP ZAP)
- **Dependency Scanning** : DÃ©tection vulnÃ©rabilitÃ©s librairies (Snyk, Dependabot)

### ConformitÃ© RÃ©glementaire

- **RGPD** : Consentement explicite, portabilitÃ© donnÃ©es, droit rectification
- **DSP2** : Strong Customer Authentication (SCA) implÃ©mentÃ©
- **PCI-DSS** : Niveau 1 (traitement > 6M transactions/an) - en cours de certification
- **LCB-FT** : DÃ©tection automatique des schÃ©mas de blanchiment (structuring, smurfing)

---

## ğŸ“ Structure du Projet

```
digitalbank-fraud-platform/
â”‚
â”œâ”€â”€ README.md                          # Ce fichier
â”œâ”€â”€ ARCHITECTURE.md                    # Documentation architecture dÃ©taillÃ©e
â”œâ”€â”€ SECURITY.md                        # Politique de sÃ©curitÃ© et reporting vulnÃ©rabilitÃ©s
â”œâ”€â”€ LICENSE                            # MIT License
â”‚
â”œâ”€â”€ api/                               # Fraud Detection API
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                    # FastAPI application entry point
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ fraud_model.py         # ML model wrapper
â”‚   â”‚   â”‚   â””â”€â”€ schemas.py             # Pydantic data models
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ predict.py             # /predict endpoint
â”‚   â”‚   â”‚   â””â”€â”€ health.py              # /health endpoint
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py              # Configuration management
â”‚   â”‚   â”‚   â””â”€â”€ logging.py             # Structured logging
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ preprocessing.py       # Feature engineering
â”‚   â”‚       â””â”€â”€ validation.py          # Input validation
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ test_api.py
â”‚   â”‚   â””â”€â”€ test_model.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ swagger.yaml                   # OpenAPI specification
â”‚
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ migrations/                    # Supabase migrations
â”‚   â”‚   â”œâ”€â”€ 001_initial_schema.sql
â”‚   â”‚   â”œâ”€â”€ 002_add_audit_logs.sql
â”‚   â”‚   â””â”€â”€ 003_add_rls_policies.sql
â”‚   â”œâ”€â”€ seeds/                         # Sample data for development
â”‚   â”‚   â””â”€â”€ transactions_sample.sql
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ backup.sh                  # Automated backup script
â”‚       â””â”€â”€ restore.sh
â”‚
â”œâ”€â”€ dashboards/
â”‚   â”œâ”€â”€ metabase/
â”‚   â”‚   â”œâ”€â”€ dashboard_security.json    # Dashboard export/import
â”‚   â”‚   â”œâ”€â”€ dashboard_support.json
â”‚   â”‚   â””â”€â”€ dashboard_infra.json
â”‚   â””â”€â”€ grafana/
â”‚       â”œâ”€â”€ prometheus.yml             # Prometheus config
â”‚       â””â”€â”€ dashboards/
â”‚           â”œâ”€â”€ api_metrics.json
â”‚           â””â”€â”€ db_metrics.json
â”‚
â”œâ”€â”€ workflows/
â”‚   â”œâ”€â”€ make/
â”‚   â”‚   â”œâ”€â”€ fraud_alert_critical.json  # Make.com workflow export
â”‚   â”‚   â”œâ”€â”€ daily_reconciliation.json
â”‚   â”‚   â””â”€â”€ auto_escalation.json
â”‚   â””â”€â”€ documentation/
â”‚       â””â”€â”€ workflow_diagrams.pdf
â”‚
â”œâ”€â”€ ml/                                # Machine Learning pipeline
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”‚   â”œâ”€â”€ 01_eda.ipynb               # Exploratory Data Analysis
â”‚   â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â”‚   â””â”€â”€ 03_model_training.ipynb
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ fraud_model_v1.pkl
â”‚   â”‚   â””â”€â”€ fraud_model_v2.pkl
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ train.py                   # Training script
â”‚   â”‚   â””â”€â”€ evaluate.py                # Model evaluation
â”‚   â””â”€â”€ mlflow/
â”‚       â””â”€â”€ mlruns/                    # MLflow tracking
â”‚
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ docker/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml         # Local dev environment
â”‚   â”‚   â””â”€â”€ docker-compose.prod.yml    # Production stack
â”‚   â”œâ”€â”€ kubernetes/                    # K8s manifests (si applicable)
â”‚   â”‚   â”œâ”€â”€ api-deployment.yaml
â”‚   â”‚   â”œâ”€â”€ api-service.yaml
â”‚   â”‚   â””â”€â”€ ingress.yaml
â”‚   â””â”€â”€ terraform/                     # IaC pour cloud provisioning
â”‚       â”œâ”€â”€ main.tf
â”‚       â”œâ”€â”€ variables.tf
â”‚       â””â”€â”€ outputs.tf
â”‚
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â””â”€â”€ rules/
â”‚   â”‚       â””â”€â”€ alerts.yml             # Alerting rules
â”‚   â””â”€â”€ grafana/
â”‚       â””â”€â”€ provisioning/
â”‚           â”œâ”€â”€ datasources.yml
â”‚           â””â”€â”€ dashboards.yml
â”‚
â”œâ”€â”€ docs/                              # Documentation complÃ¨te
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ swagger.yaml
â”‚   â”œâ”€â”€ user_guide/
â”‚   â”‚   â””â”€â”€ Manuel_Utilisateur.md
â”‚   â”œâ”€â”€ admin_guide/
â”‚   â”‚   â””â”€â”€ Guide_Installation.md
â”‚   â””â”€â”€ diagrams/
â”‚       â”œâ”€â”€ architecture.png
â”‚       â””â”€â”€ data_flow.png
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.sh                       # Setup complet environnement dev
â”‚   â”œâ”€â”€ deploy.sh                      # DÃ©ploiement production
â”‚   â””â”€â”€ run_tests.sh                   # Lancement tests automatisÃ©s
â”‚
â””â”€â”€ .github/                           # CI/CD
    â””â”€â”€ workflows/
        â”œâ”€â”€ ci.yml                     # Tests + lint sur chaque PR
        â””â”€â”€ cd.yml                     # DÃ©ploiement automatique
```

---

## ğŸš€ Instructions GÃ©nÃ©rales d'Utilisation

### PrÃ©requis

- **Comptes requis** :
  - Supabase (plan gratuit suffisant pour dÃ©veloppement)
  - Make.com (plan Free : 1000 opÃ©rations/mois)
  - Metabase Cloud ou self-hosted
  - Docker Desktop (si dÃ©ploiement local)

- **Logiciels** :
  - Git
  - Python 3.10+
  - Node.js 18+ (pour outils frontend si applicable)
  - PostgreSQL client (psql)

### Installation Rapide (DÃ©veloppement)

```bash
# 1. Cloner le repository
git clone https://github.com/esic-paris/digitalbank-fraud-platform.git
cd digitalbank-fraud-platform

# 2. Setup base de donnÃ©es
psql -h <SUPABASE_HOST> -U postgres -d postgres -f database/migrations/001_initial_schema.sql

# 3. Configuration API
cd api
cp .env.example .env
# Ã‰diter .env avec vos credentials Supabase
pip install -r requirements.txt

# 4. Lancer l'API
uvicorn app.main:app --reload --port 8000

# 5. Tester l'API
curl http://localhost:8000/health
# Response: {"status": "healthy", "model_loaded": true}
```

### AccÃ¨s aux Dashboards

1. **Metabase** : 
   - URL : https://metabase.digitalbank-fraud.esic.cloud
   - Connexion : SSO via Google Workspace ESIC

2. **Grafana** :
   - URL : https://grafana.digitalbank-fraud.esic.cloud
   - Login : admin / (voir Vault secrets)

3. **Make.com** :
   - URL : https://make.com/scenarios
   - Team : ESIC-DigitalBank-Team

### DÃ©ploiement Production

Voir le document dÃ©diÃ© : **docs/admin_guide/Guide_Installation_Deploiement.md**

---

## ğŸ“Š MÃ©triques de SuccÃ¨s

### KPI Projet

| MÃ©trique | Objectif | Mesure Actuelle |
|----------|----------|-----------------|
| Accuracy modÃ¨le ML | > 98% | 98,7% (sur test set) |
| Recall (fraudes dÃ©tectÃ©es) | > 95% | 96,2% |
| Taux de faux positifs | < 2% | 1,8% |
| Latence API (p95) | < 100ms | 87ms |
| DisponibilitÃ© plateforme | > 99,5% | 99,7% (30 derniers jours) |
| Temps rÃ©solution alertes | < 15min | 12min (moyenne) |

---

## ğŸ”„ Roadmap Futures Ã‰volutions

### Phase 2 (Q1 2026)
- [ ] IntÃ©gration dÃ©tection de fraude sur virements (actuellement CB uniquement)
- [ ] Dashboard mobile (React Native)
- [ ] API GraphQL en complÃ©ment REST
- [ ] Support multi-devises (actuellement EUR uniquement)

### Phase 3 (Q2 2026)
- [ ] Deep Learning model (LSTM pour dÃ©tection patterns temporels)
- [ ] Real-time streaming avec Apache Kafka
- [ ] Multi-rÃ©gion deployment (EU + US)
- [ ] Open Banking API PSD2 compliance

---

## ğŸ‘¨â€ğŸ’» Contributeurs

**Ã‰quipe Projet ESIC Paris â€“ Promo 2025**

- **Chef de Projet** : [Nom] - Architecture globale, coordination
- **Tech Lead** : [Nom] - API Python, ML pipeline
- **Data Engineer** : [Nom] - Base de donnÃ©es, ETL
- **DevOps** : [Nom] - Infrastructure, CI/CD
- **Business Analyst** : [Nom] - Dashboards, spÃ©cifications fonctionnelles

**Encadrement AcadÃ©mique**
- Tuteur : [Nom Professeur], ESIC Paris
- Expert Externe : [Nom], Senior Security Architect @ [Banque]

---

## ğŸ“ Support et Contact

- **Issues GitHub** : https://github.com/esic-paris/digitalbank-fraud-platform/issues
- **Email Ã©quipe** : digitalbank-fraud@esic.edu
- **Slack** : #digitalbank-fraud-platform
- **Documentation complÃ¨te** : https://docs.digitalbank-fraud.esic.cloud

---

## ğŸ“„ Licence

Ce projet est dÃ©veloppÃ© dans un cadre pÃ©dagogique et n'est pas destinÃ© Ã  une utilisation en production.

**Licence MIT** - Voir fichier LICENSE pour dÃ©tails.

---

## ğŸ™ Remerciements

- **ESIC Paris** pour l'encadrement et les ressources mises Ã  disposition
- **Supabase Team** pour le support technique sur PostgreSQL RLS
- **Kaggle Community** pour le dataset "Credit Card Fraud Detection"
- **Open Source Projects** : FastAPI, Metabase, Grafana, Prometheus

---

**DerniÃ¨re mise Ã  jour** : Janvier 2026  
**Version** : 1.0.0  
**Statut** : âœ… Production Ready (environnement acadÃ©mique)
